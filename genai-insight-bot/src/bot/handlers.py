from telegram import Update
from telegram.ext import ContextTypes, CommandHandler, MessageHandler, filters, ConversationHandler
import logging
from utils.file_parser import file_parser
from database.operations import db
from utils.visualizer import visualizer
import tempfile
import os
from telegram import ReplyKeyboardMarkup, ReplyKeyboardRemove

def get_main_keyboard():
    """–û—Å–Ω–æ–≤–Ω–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å –≥–ª–∞–≤–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏"""
    keyboard = [
        ['üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏', 'üîç –ü–æ–∏—Å–∫'],
        ['‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å', 'üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'],
        ['üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ', 'üõ† –û—á–∏—Å—Ç–∫–∞'],
        ['üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏', '‚ÑπÔ∏è –ü–æ–º–æ—â—å']
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

def get_cancel_keyboard():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Ç–æ–ª—å–∫–æ —Å –æ—Ç–º–µ–Ω–æ–π"""
    keyboard = [['‚ùå –û—Ç–º–µ–Ω–∞']]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

def get_visualization_keyboard():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
    keyboard = [
        ['üìä –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π', 'üîó –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π'],
        ['üéØ –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞', 'üè¢ –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–∞–Ω–∏–π'],
        ['‚ùå –û—Ç–º–µ–Ω–∞']
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

def get_cleanup_keyboard():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏"""
    keyboard = [
        ['üßπ –û—á–∏—Å—Ç–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã', '‚ùå –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞'],
        ['‚ùå –û—Ç–º–µ–Ω–∞']
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

logger = logging.getLogger(__name__)

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è ConversationHandler
WAITING_TOPIC, WAITING_SEARCH, WAITING_COMPARE = range(3)

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = """
ü§ñ **GenAI Insight Bot**

–ë–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏ AI –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

üîç **–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ç–µ–º–∞–º
‚Ä¢ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤  
‚Ä¢ –ê–Ω–∞–ª–∏–∑ –Ω–∞–≤—ã–∫–æ–≤ –∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

üëá **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã:**
"""
    await update.message.reply_text(
        welcome_text,
        reply_markup=get_main_keyboard(),
        parse_mode='Markdown'
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """
ü§ñ **GenAI Insight Bot - –ü–æ–º–æ—â—å**

üëá **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã:**

**üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** `/recommend [—Ç–µ–º–∞]`
**üîç –ü–æ–∏—Å–∫** `/search [–∑–∞–ø—Ä–æ—Å]` 
**‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å** `/compare [X] vs [Y]`
**üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** `/stats`

**üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ** `/upload`
**üõ† –û—á–∏—Å—Ç–∫–∞** `/cleanup` `/clear`
**üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏** `/visualize`

**‚ùå –û—Ç–º–µ–Ω–∞** `/cancel` - –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
"""
    await update.message.reply_text(
        help_text,
        reply_markup=get_main_keyboard(),
        parse_mode='Markdown'
    )

async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    telegram_id = str(update.effective_user.id)
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        people = db.get_all_people(telegram_id)
        
        if not people:
            await update.message.reply_text(
                "üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /upload –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.",
                reply_markup=get_main_keyboard()
            )
            return
        
        # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏
        unique_names = set()
        unique_people_map = {}
        
        for person in people:
            normalized_name = person.name.lower().strip()
            unique_names.add(normalized_name)
            if normalized_name not in unique_people_map:
                unique_people_map[normalized_name] = person
        
        unique_people_list = list(unique_people_map.values())
        duplicate_count = len(people) - len(unique_people_list)
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
        companies = {}
        skills_count = {}
        positions_count = {}
        
        for person in unique_people_list:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
            company = person.company or "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
            companies[company] = companies.get(company, 0) + 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞–≤—ã–∫–∞–º
            for skill in person.skills:
                skills_count[skill] = skills_count.get(skill, 0) + 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º
            position = person.position or "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
            positions_count[position] = positions_count.get(position, 0) + 1
        
        # –¢–æ–ø –∑–Ω–∞—á–µ–Ω–∏—è
        top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]
        top_skills = sorted(skills_count.items(), key=lambda x: x[1], reverse=True)[:8]
        top_positions = sorted(positions_count.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
        insights = []
        if top_companies and top_companies[0][0] != "–ù–µ —É–∫–∞–∑–∞–Ω–∞":
            insights.append(f"üè¢ **{top_companies[0][0]}** - –ª–∏–¥–µ—Ä –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤")
        if top_skills:
            insights.append(f"üõ† **{top_skills[0][0]}** - —Å–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –Ω–∞–≤—ã–∫")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        companies_with_data = len([c for c in companies.keys() if c != "–ù–µ —É–∫–∞–∑–∞–Ω–∞"])
        positions_with_data = len([p for p in positions_count.keys() if p != "–ù–µ —É–∫–∞–∑–∞–Ω–∞"])
        
        stats_text = f"""
üìä **–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**

üë• **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤:** {len(unique_people_list)}
üìù **–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ:** {len(people)}
üè≠ **–ö–æ–º–ø–∞–Ω–∏–π:** {companies_with_data}
üëî **–î–æ–ª–∂–Ω–æ—Å—Ç–µ–π:** {positions_with_data}

üîç **–ò–Ω—Å–∞–π—Ç—ã:**
{chr(10).join(f'‚Ä¢ {insight}' for insight in insights) if insights else '‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}

üè¢ **–¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π:**
{chr(10).join(f'‚Ä¢ {company}: {count}' for company, count in top_companies)}

üõ† **–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –Ω–∞–≤—ã–∫–∏:**
{chr(10).join(f'‚Ä¢ {skill}: {count}' for skill, count in top_skills)}

üëî **–û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏:**
{chr(10).join(f'‚Ä¢ {position}: {count}' for position, count in top_positions)}
"""
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if duplicate_count > 0:
            stats_text += f"\n‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {duplicate_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤**\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/cleanup` –¥–ª—è –æ—á–∏—Å—Ç–∫–∏"
        
        await update.message.reply_text(
            stats_text, 
            parse_mode='Markdown',
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in stats_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            reply_markup=get_main_keyboard()
        )

async def recommend_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    telegram_id = str(update.effective_user.id)
    """–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ"""
    # –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –≤—ã–∑–≤–∞–Ω–∞ —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–º—É
    if not context.args and update.message.text == 'üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏':
        await update.message.reply_text(
            "üéØ –í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:\n\n–ü—Ä–∏–º–µ—Ä: AI, Computer Vision, NLP",
            reply_markup=get_cancel_keyboard()
        )
        return WAITING_TOPIC
    
    if not context.args and update.message.text != 'üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏':
        await update.message.reply_text(
            "–£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É: /recommend [—Ç–µ–º–∞]\n–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É 'üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'",
            reply_markup=get_main_keyboard()
        )
        return
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–º—É –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    if context.args:
        topic = " ".join(context.args).lower().strip()
    else:
        topic = update.message.text.lower().strip()
    
    try:
        await update.message.chat.send_action(action="typing")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∏–∑ –±–∞–∑—ã
        people = db.get_all_people(telegram_id)
        
        if not people:
            await update.message.reply_text(
                "‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ /upload",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ç–µ–º–µ
        matched_experts = []
        seen_names = set()
        
        for person in people:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            if person.name in seen_names:
                continue
                
            score = 0
            matches = []
            
            # 1. –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
            if topic in person.name.lower():
                score += 3
                matches.append("–∏–º—è")
            
            # 2. –ü–æ–∏—Å–∫ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
            if person.position:
                position_lower = person.position.lower()
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if topic in position_lower:
                    score += 2
                    matches.append("–¥–æ–ª–∂–Ω–æ—Å—Ç—å")
                # –ü–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤–∞–º
                elif any(word in position_lower for word in topic.split() if len(word) > 2):
                    score += 1
                    matches.append("–¥–æ–ª–∂–Ω–æ—Å—Ç—å")
            
            # 3. –ü–æ–∏—Å–∫ –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
            if person.company:
                company_lower = person.company.lower()
                if topic in company_lower:
                    score += 2
                    matches.append("–∫–æ–º–ø–∞–Ω–∏—è")
                elif any(word in company_lower for word in topic.split() if len(word) > 2):
                    score += 1
                    matches.append("–∫–æ–º–ø–∞–Ω–∏—è")
            
            # 4. –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–≤—ã–∫–∞–º (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)
            skill_matches = []
            for skill in person.skills:
                skill_lower = skill.lower()
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if topic in skill_lower:
                    skill_matches.append(skill)
                    score += 2
                # –ü–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤–∞–º
                elif any(word in skill_lower for word in topic.split() if len(word) > 2):
                    skill_matches.append(skill)
                    score += 1
                # –ü–æ–∏—Å–∫ –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º
                elif await _check_skill_synonyms(topic, skill_lower):
                    skill_matches.append(skill)
                    score += 1
            
            if skill_matches:
                matches.append(f"–Ω–∞–≤—ã–∫–∏: {', '.join(skill_matches[:3])}")
            
            # 5. –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)
            project_matches = []
            for project in person.projects:
                project_lower = project.lower()
                if topic in project_lower:
                    project_matches.append(project)
                    score += 2
                elif any(word in project_lower for word in topic.split() if len(word) > 2):
                    project_matches.append(project)
                    score += 1
            
            if project_matches:
                matches.append(f"–ø—Ä–æ–µ–∫—Ç—ã: {', '.join(project_matches[:2])}")
            
            # 6. –ü–æ–∏—Å–∫ –ø–æ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º
            if score == 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
                related_score = await _check_related_topics(topic, person)
                if related_score > 0:
                    score = related_score
                    matches.append("—Å–≤—è–∑–∞–Ω–Ω–∞—è —Ç–µ–º–∞")
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞ (–¥–∞–∂–µ —Å –Ω–∏–∑–∫–∏–º score)
            if score > 0:
                matched_experts.append({
                    'person': person,
                    'score': score,
                    'matches': matches
                })
                seen_names.add(person.name)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        matched_experts.sort(key=lambda x: x['score'], reverse=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        if not matched_experts:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            await _show_all_experts_fallback(update, topic, people)
            return ConversationHandler.END

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        recommendations_data = []
        for expert in matched_experts[:10]:
            recommendations_data.append({
                'name': expert['person'].name,
                'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'skills': expert['person'].skills,
                'score': expert['score'],
                'matches': expert['matches']
            })

        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if recommendations_data:
            try:
                # 1. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (—Å—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞)
                chart_html = visualizer.create_recommendations_chart(recommendations_data)
                
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(chart_html)
                    temp_file1 = f.name

                await update.message.reply_document(
                    document=open(temp_file1, 'rb'),
                    filename=f"recommendations_chart_{topic}.html",
                    caption=f"üìä –î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ç–µ–º–µ: {topic}"
                )
                os.unlink(temp_file1)
                
                # 2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)
                if len(recommendations_data) >= 3:
                    connections = []
                    people_data_for_graph = []
                    
                    for expert in matched_experts[:8]:
                        people_data_for_graph.append({
                            'name': expert['person'].name,
                            'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                            'skills': expert['person'].skills,
                            'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                        })
                    
                    for i in range(len(people_data_for_graph)):
                        for j in range(i + 1, len(people_data_for_graph)):
                            common_skills = set(people_data_for_graph[i]['skills']) & set(people_data_for_graph[j]['skills'])
                            if common_skills:
                                connections.append((i, j))
                            elif (people_data_for_graph[i]['company'] == people_data_for_graph[j]['company'] and 
                                  people_data_for_graph[i]['company'] != '–ù–µ —É–∫–∞–∑–∞–Ω–∞'):
                                connections.append((i, j))
                    
                    graph_html = visualizer.create_network_graph(people_data_for_graph, connections)
                    
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                        f.write(graph_html)
                        temp_file2 = f.name

                    await update.message.reply_document(
                        document=open(temp_file2, 'rb'),
                        filename=f"network_graph_{topic}.html",
                        caption=f"üîó –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ç–µ–º–µ: {topic}"
                    )
                    os.unlink(temp_file2)
                
                # 3. –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞–≤—ã–∫–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–≤—ã–∫–∏)
                skills_data = []
                for expert in matched_experts[:15]:
                    if expert['person'].skills:
                        skills_data.append({
                            'name': expert['person'].name,
                            'skills': expert['person'].skills,
                            'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                        })
                
                if skills_data:
                    heatmap_html = visualizer.create_skills_heatmap(skills_data)
                    
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                        f.write(heatmap_html)
                        temp_file3 = f.name

                    await update.message.reply_document(
                        document=open(temp_file3, 'rb'),
                        filename=f"skills_heatmap_{topic}.html",
                        caption=f"üéØ –ù–∞–≤—ã–∫–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ç–µ–º–µ: {topic}"
                    )
                    os.unlink(temp_file3)
                
                # 4. –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–∞–Ω–∏–π
                company_data = []
                for expert in matched_experts:
                    company_data.append({
                        'name': expert['person'].name,
                        'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                        'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                    })
                
                company_html = visualizer.create_company_distribution(company_data)
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(company_html)
                    temp_file4 = f.name

                await update.message.reply_document(
                    document=open(temp_file4, 'rb'),
                    filename=f"companies_{topic}.html",
                    caption=f"üè¢ –ö–æ–º–ø–∞–Ω–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ç–µ–º–µ: {topic}"
                )
                os.unlink(temp_file4)
                
            except Exception as e:
                logger.error(f"Error creating visualization: {e}")
                await update.message.reply_text("‚ö†Ô∏è –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –Ω–æ –≤–æ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—Ç–æ–ø-5)
        top_experts = matched_experts[:5]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –±–µ–∑ Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        response = f"üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ: {topic}\n\n"
        response += f"üìä –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {len(matched_experts)}\n\n"
        
        for i, expert_data in enumerate(top_experts, 1):
            person = expert_data['person']
            matches = expert_data['matches']
            
            response += f"{i}. {person.name}\n"
            response += f"   üè¢ {person.position or '–î–æ–ª–∂–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞'}"
            if person.company:
                response += f" –≤ {person.company}"
            response += "\n"
            
            if matches:
                response += f"   ‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏—è: {', '.join(matches[:2])}\n"
            
            if person.skills:
                skills_preview = ', '.join(person.skills[:3])
                if len(person.skills) > 3:
                    skills_preview += f" –∏ –µ—â—ë {len(person.skills) - 3}"
                response += f"   üõ† –ù–∞–≤—ã–∫–∏: {skills_preview}\n"
            
            if person.projects:
                projects_preview = ', '.join(person.projects[:2])
                if len(person.projects) > 2:
                    projects_preview += f" –∏ –µ—â—ë {len(person.projects) - 2}"
                response += f"   üöÄ –ü—Ä–æ–µ–∫—Ç—ã: {projects_preview}\n"
            
            response += "\n"
        
        if len(matched_experts) > 5:
            response += f"üìà –ò –µ—â—ë {len(matched_experts) - 5} —ç–∫—Å–ø–µ—Ä—Ç–æ–≤...\n"
            response += "üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /search –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        response += await _generate_recommendation_analytics(matched_experts, topic)
        
        await update.message.reply_text(
            response,
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in recommend_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.",
            reply_markup=get_main_keyboard()
        )
    
    return ConversationHandler.END

async def _check_skill_synonyms(topic: str, skill: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –Ω–∞–≤—ã–∫–æ–≤"""
    synonyms = {
        'ai': ['artificial intelligence', 'machine learning', 'deep learning', 'neural networks'],
        'ml': ['machine learning', 'ai', 'deep learning'],
        'dl': ['deep learning', 'neural networks'],
        'cv': ['computer vision', 'image processing'],
        'nlp': ['natural language processing', 'text processing', 'language models'],
        '–ø—Ä–æ–µ–∫—Ç—ã': ['projects', 'work', 'experience', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '—Å–æ–∑–¥–∞–Ω–∏–µ'],
        'project': ['–ø—Ä–æ–µ–∫—Ç—ã', '—Ä–∞–±–æ—Ç–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞'],
        'research': ['–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '–Ω–∞—É–∫–∞', '–∞–∫–∞–¥–µ–º–∏—è'],
        '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ': ['management', 'leadership', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ'],
        '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞': ['development', 'engineering', 'programming'],
        '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ': ['programming', 'coding', 'development'],
        '–∞–Ω–∞–ª–∏–∑': ['analysis', 'analytics', 'research'],
        '–¥–∞–Ω–Ω—ã–µ': ['data', 'analytics', 'analysis'],
        'leadership': ['—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç'],
        'management': ['—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ']
    }
    
    for main_topic, synonym_list in synonyms.items():
        if topic in main_topic or main_topic in topic:
            if any(synonym in skill for synonym in synonym_list):
                return True
    return False

async def _check_related_topics(topic: str, person) -> int:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã"""
    related_topics = {
        'ai': ['machine learning', 'deep learning', 'neural networks', 'computer vision', 'nlp'],
        'ml': ['ai', 'deep learning', 'data science', 'statistics'],
        'programming': ['coding', 'development', 'software engineering', 'python', 'java'],
        'data': ['data science', 'analytics', 'big data', 'database'],
        'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes'],
        'web': ['frontend', 'backend', 'fullstack', 'javascript', 'react'],
        '–ø—Ä–æ–µ–∫—Ç—ã': ['projects', 'development', 'engineering', 'product'],
        '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ': ['management', 'leadership', 'team', 'project'],
        '–∞–Ω–∞–ª–∏–∑': ['analysis', 'research', 'data', 'analytics'],
        '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞': ['development', 'programming', 'engineering', 'coding']
    }
    
    score = 0
    for main_topic, related_list in related_topics.items():
        if topic in main_topic or main_topic in topic:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–≤—ã–∫–∏ –Ω–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
            for skill in person.skills:
                skill_lower = skill.lower()
                if any(related in skill_lower for related in related_list):
                    score += 1
                    break
    return score

async def handle_recommend_topic(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ —Ç–µ–º—ã –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    context.user_data['topic'] = update.message.text
    context.args = [update.message.text]
    return await recommend_command(update, context)

async def _show_all_experts_fallback(update: Update, topic: str, people: list):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –µ—Å–ª–∏ –ø–æ —Ç–µ–º–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"""
    unique_people = {}
    for person in people:
        if person.name not in unique_people:
            unique_people[person.name] = person
    
    unique_list = list(unique_people.values())
    
    if len(unique_list) <= 10:
        experts_to_show = unique_list
    else:
        import random
        experts_to_show = random.sample(unique_list, 10)
    
    response = f"üîç –ü–æ —Ç–µ–º–µ '{topic}' —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n\n"
    response += "üí° –í–æ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏–∑ –±–∞–∑—ã:\n\n"
    
    for i, person in enumerate(experts_to_show, 1):
        response += f"{i}. {person.name}\n"
        if person.position:
            response += f"   {person.position}"
            if person.company:
                response += f" –≤ {person.company}"
            response += "\n"
        
        if person.skills:
            skills_preview = ', '.join(person.skills[:3])
            response += f"   üõ† {skills_preview}\n"
        
        response += "\n"
    
    response += f"üìä –í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –±–∞–∑–µ: {len(unique_list)}\n\n"
    response += "üí° –°–æ–≤–µ—Ç—ã:\n"
    response += "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stats –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã\n"
    response += "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞\n"
    response += "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /search –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n"
    response += "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /list —á—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"
    
    await update.message.reply_text(
        response,
        reply_markup=get_main_keyboard()
    )

async def handle_recommend_topic(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ —Ç–µ–º—ã –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    context.user_data['topic'] = update.message.text
    context.args = [update.message.text]
    return await recommend_command(update, context)

async def _generate_recommendation_analytics(matched_experts: list, topic: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º"""
    if not matched_experts:
        return ""
    
    analytics = "\nüîç –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º:\n"
    
    companies = {}
    positions = {}
    all_skills = []
    
    for expert in matched_experts:
        person = expert['person']
        
        if person.company:
            companies[person.company] = companies.get(person.company, 0) + 1
        
        if person.position:
            positions[person.position] = positions.get(person.position, 0) + 1
        
        all_skills.extend(person.skills)
    
    if companies:
        top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:3]
        analytics += f"‚Ä¢ üè¢ –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–∏: {', '.join([f'{company} ({count})' for company, count in top_companies])}\n"
    
    if positions:
        top_positions = sorted(positions.items(), key=lambda x: x[1], reverse=True)[:3]
        analytics += f"‚Ä¢ üëî –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–æ–ª–∏: {', '.join([f'{position} ({count})' for position, count in top_positions])}\n"
    
    if all_skills:
        unique_skills = len(set(all_skills))
        analytics += f"‚Ä¢ üõ† –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {unique_skills}\n"
    
    avg_score = sum(expert['score'] for expert in matched_experts) / len(matched_experts)
    if avg_score > 2:
        relevance = "–≤—ã—Å–æ–∫–∞—è"
    elif avg_score > 1:
        relevance = "—Å—Ä–µ–¥–Ω—è—è"
    else:
        relevance = "–Ω–∏–∑–∫–∞—è"
    
    analytics += f"‚Ä¢ üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance} ({avg_score:.1f} –±–∞–ª–ª–æ–≤)\n"
    
    if avg_score < 1.5:
        analytics += f"‚Ä¢ üí° –°–æ–≤–µ—Ç: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã\n"
    
    return analytics

async def search_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    telegram_id = str(update.effective_user.id)
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    # –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –≤—ã–∑–≤–∞–Ω–∞ —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
    if not context.args and update.message.text == 'üîç –ü–æ–∏—Å–∫':
        await update.message.reply_text(
            "üîç **–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞:**\n\n"
            "–ú–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å –ø–æ:\n"
            "‚Ä¢ –ò–º–µ–Ω–∏\n‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–∏\n‚Ä¢ –ù–∞–≤—ã–∫—É\n‚Ä¢ –î–æ–ª–∂–Ω–æ—Å—Ç–∏\n‚Ä¢ –ü—Ä–æ–µ–∫—Ç–∞–º",
            reply_markup=get_cancel_keyboard(),
            parse_mode='Markdown'
        )
        return WAITING_SEARCH
    
    if not context.args and update.message.text != 'üîç –ü–æ–∏—Å–∫':
        await update.message.reply_text(
            "üîç –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /search [–∑–∞–ø—Ä–æ—Å]\n–ò–ª–∏ –∫–Ω–æ–ø–∫—É 'üîç –ü–æ–∏—Å–∫'",
            reply_markup=get_main_keyboard()
        )
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    if context.args:
        query = " ".join(context.args).lower().strip()
    else:
        query = update.message.text.lower().strip()
    
    try:
        await update.message.chat.send_action(action="typing")
        
        people = db.get_all_people(telegram_id)
        
        if not people:
            await update.message.reply_text(
                "‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END
        
        # –ü–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        matched_experts = []
        seen_names = set()
        
        for person in people:
            if person.name in seen_names:
                continue
                
            score = 0
            matches = []
            
            # –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏
            if query in person.name.lower():
                score += 3
                matches.append(f"–∏–º—è: {person.name}")
            
            # –ü–æ–∏—Å–∫ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
            if person.position and query in person.position.lower():
                score += 2
                matches.append(f"–¥–æ–ª–∂–Ω–æ—Å—Ç—å: {person.position}")
            
            # –ü–æ–∏—Å–∫ –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏
            if person.company and query in person.company.lower():
                score += 2
                matches.append(f"–∫–æ–º–ø–∞–Ω–∏—è: {person.company}")
            
            # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–≤—ã–∫–∞–º
            skill_matches = []
            for skill in person.skills:
                if query in skill.lower():
                    skill_matches.append(skill)
                    score += 1
            
            if skill_matches:
                matches.append(f"–Ω–∞–≤—ã–∫–∏: {', '.join(skill_matches[:2])}")
            
            # –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º
            project_matches = []
            for project in person.projects:
                if query in project.lower():
                    project_matches.append(project)
                    score += 1
            
            if project_matches:
                matches.append(f"–ø—Ä–æ–µ–∫—Ç—ã: {', '.join(project_matches[:2])}")
            
            if score > 0:
                matched_experts.append({
                    'person': person,
                    'score': score,
                    'matches': matches
                })
                seen_names.add(person.name)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        matched_experts.sort(key=lambda x: x['score'], reverse=True)
        
        if not matched_experts:
            await update.message.reply_text(
                f"üîç –ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                f"‚Ä¢ –î—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞\n"
                f"‚Ä¢ –ë–æ–ª–µ–µ –æ–±—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        search_results_data = []
        for expert in matched_experts[:15]:
            search_results_data.append({
                'name': expert['person'].name,
                'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'skills': expert['person'].skills,
                'score': expert['score'],
                'matches': expert['matches']
            })
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if search_results_data:
            try:
                # 1. –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
                chart_html = visualizer.create_recommendations_chart(search_results_data)
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(chart_html)
                    temp_file1 = f.name

                await update.message.reply_document(
                    document=open(temp_file1, 'rb'),
                    filename=f"search_results_{query}.html",
                    caption=f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: {query}"
                )
                os.unlink(temp_file1)
                
                # 2. –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
                if len(search_results_data) >= 3:
                    connections = []
                    people_data_for_graph = []
                    
                    for expert in matched_experts[:8]:
                        people_data_for_graph.append({
                            'name': expert['person'].name,
                            'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                            'skills': expert['person'].skills,
                            'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                        })
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    for i in range(len(people_data_for_graph)):
                        for j in range(i + 1, len(people_data_for_graph)):
                            # –°–≤—è–∑—å –ø–æ –æ–±—â–∏–º –Ω–∞–≤—ã–∫–∞–º
                            common_skills = set(people_data_for_graph[i]['skills']) & set(people_data_for_graph[j]['skills'])
                            if common_skills:
                                connections.append((i, j))
                            # –°–≤—è–∑—å –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏
                            elif (people_data_for_graph[i]['company'] == people_data_for_graph[j]['company'] and 
                                  people_data_for_graph[i]['company'] != '–ù–µ —É–∫–∞–∑–∞–Ω–∞'):
                                connections.append((i, j))
                            # –°–≤—è–∑—å –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
                            elif (people_data_for_graph[i]['position'] == people_data_for_graph[j]['position'] and 
                                  people_data_for_graph[i]['position'] != '–ù–µ —É–∫–∞–∑–∞–Ω–∞'):
                                connections.append((i, j))
                    
                    graph_html = visualizer.create_network_graph(people_data_for_graph, connections)
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                        f.write(graph_html)
                        temp_file2 = f.name

                    await update.message.reply_document(
                        document=open(temp_file2, 'rb'),
                        filename=f"search_network_{query}.html",
                        caption=f"üîó –°–≤—è–∑–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {query}"
                    )
                    os.unlink(temp_file2)
                
                # 3. –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞–≤—ã–∫–æ–≤
                if any(expert['person'].skills for expert in matched_experts):
                    skills_data = []
                    for expert in matched_experts[:15]:
                        if expert['person'].skills:
                            skills_data.append({
                                'name': expert['person'].name,
                                'skills': expert['person'].skills,
                                'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                            })
                    
                    heatmap_html = visualizer.create_skills_heatmap(skills_data)
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                        f.write(heatmap_html)
                        temp_file3 = f.name

                    await update.message.reply_document(
                        document=open(temp_file3, 'rb'),
                        filename=f"search_skills_{query}.html",
                        caption=f"üéØ –ù–∞–≤—ã–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {query}"
                    )
                    os.unlink(temp_file3)
                
                # 4. –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–∞–Ω–∏–π
                company_data = []
                for expert in matched_experts:
                    company_data.append({
                        'name': expert['person'].name,
                        'company': expert['person'].company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                        'position': expert['person'].position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                    })
                
                company_html = visualizer.create_company_distribution(company_data)
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(company_html)
                    temp_file4 = f.name

                await update.message.reply_document(
                    document=open(temp_file4, 'rb'),
                    filename=f"search_companies_{query}.html",
                    caption=f"üè¢ –ö–æ–º–ø–∞–Ω–∏–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {query}"
                )
                os.unlink(temp_file4)
                
            except Exception as e:
                logger.error(f"Error creating search visualizations: {e}")
                await update.message.reply_text("‚ö†Ô∏è –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        
        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        top_experts = matched_experts[:10]
        response = f"üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: '{query}'**\n\n"
        response += f"üìä –ù–∞–π–¥–µ–Ω–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {len(matched_experts)}\n\n"
        
        for i, expert_data in enumerate(top_experts, 1):
            person = expert_data['person']
            matches = expert_data['matches']
            
            response += f"{i}. **{person.name}**\n"
            if person.position:
                response += f"   {person.position}"
                if person.company:
                    response += f" –≤ {person.company}"
                response += "\n"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if matches:
                response += f"   ‚úÖ {matches[0]}\n"
            
            if person.skills:
                skills_preview = ', '.join(person.skills[:3])
                response += f"   üõ† {skills_preview}\n"
            
            response += "\n"
        
        if len(matched_experts) > 10:
            response += f"üìà ... –∏ –µ—â—ë {len(matched_experts) - 10} —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"
        
        await update.message.reply_text(
            response,
            parse_mode='Markdown',
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in search_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ.",
            reply_markup=get_main_keyboard()
        )
    
    return ConversationHandler.END

async def handle_search_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"""
    context.args = [update.message.text]
    return await search_command(update, context)

async def compare_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–≤—É—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    if not context.args and update.message.text == '‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å':
        await update.message.reply_text(
            "‚öñÔ∏è **–í–≤–µ–¥–∏—Ç–µ –∏–º–µ–Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:**\n\n–§–æ—Ä–º–∞—Ç: `–ò–º—è1 vs –ò–º—è2`\n–ü—Ä–∏–º–µ—Ä: `Sam Altman vs Timnit Gebru`",
            reply_markup=get_cancel_keyboard(),
            parse_mode='Markdown'
        )
        return WAITING_COMPARE
    
    if not context.args and update.message.text != '‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å':
        await update.message.reply_text(
            "‚ùå –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /compare [–ò–º—è1] vs [–ò–º—è2]\n–ò–ª–∏ –∫–Ω–æ–ø–∫—É '‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å'",
            reply_markup=get_main_keyboard()
        )
        return

    try:
        if context.args:
            query = " ".join(context.args)
        else:
            query = update.message.text

        if " vs " not in query:
            await update.message.reply_text(
                "‚ùå –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'vs' –º–µ–∂–¥—É –∏–º–µ–Ω–∞–º–∏",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END

        await update.message.chat.send_action(action="typing")
        
        names = query.split(" vs ")
        person_x = names[0].strip()
        person_y = names[1].strip()

        logger.info(f"üîÑ –°—Ä–∞–≤–Ω–∏–≤–∞—é: {person_x} vs {person_y}")

        expert_x = db.get_person_by_name(person_x)
        expert_y = db.get_person_by_name(person_y)

        if not expert_x or not expert_y:
            await update.message.reply_text(
                "‚ùå –û–¥–∏–Ω –∏–ª–∏ –æ–±–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END

        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        person_x_data = {
            'name': expert_x.name,
            'position': expert_x.position,
            'company': expert_x.company,
            'skills': expert_x.skills,
            'projects': expert_x.projects
        }

        person_y_data = {
            'name': expert_y.name,
            'position': expert_y.position,
            'company': expert_y.company,
            'skills': expert_y.skills,
            'projects': expert_y.projects
        }

        scores = {
            'skills_score_x': len(expert_x.skills),
            'skills_score_y': len(expert_y.skills),
            'experience_score_x': 7 if "Senior" in expert_x.position else 5,
            'experience_score_y': 7 if "Senior" in expert_y.position else 5,
            'projects_score_x': len(expert_x.projects),
            'projects_score_y': len(expert_y.projects),
            'publications_score_x': 6,
            'publications_score_y': 6,
            'influence_score_x': 8 if "CEO" in expert_x.position else 5,
            'influence_score_y': 8 if "CEO" in expert_y.position else 5
        }

        chart_html = visualizer.create_people_comparison_chart(person_x_data, person_y_data, scores)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as f:
            f.write(chart_html)
            temp_file = f.name

        try:
            await update.message.reply_document(
                document=open(temp_file, 'rb'),
                filename=f"comparison_{person_x}_vs_{person_y}.html",
                caption=f"üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: {person_x} vs {person_y}"
            )
        finally:
            os.unlink(temp_file)

        report = f"""
‚öñÔ∏è **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤:**

**{person_x}**
‚Ä¢ –î–æ–ª–∂–Ω–æ—Å—Ç—å: {expert_x.position}
‚Ä¢ –ö–æ–º–ø–∞–Ω–∏—è: {expert_x.company}
‚Ä¢ –ù–∞–≤—ã–∫–∏: {', '.join(expert_x.skills[:5])}
‚Ä¢ –ü—Ä–æ–µ–∫—Ç—ã: {len(expert_x.projects)}

**{person_y}**
‚Ä¢ –î–æ–ª–∂–Ω–æ—Å—Ç—å: {expert_y.position}
‚Ä¢ –ö–æ–º–ø–∞–Ω–∏—è: {expert_y.company}
‚Ä¢ –ù–∞–≤—ã–∫–∏: {', '.join(expert_y.skills[:5])}
‚Ä¢ –ü—Ä–æ–µ–∫—Ç—ã: {len(expert_y.projects)}
"""
        await update.message.reply_text(
            report, 
            parse_mode='Markdown',
            reply_markup=get_main_keyboard()
        )
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ compare_command: {e}")
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞: {str(e)}",
            reply_markup=get_main_keyboard()
        )
    
    return ConversationHandler.END

async def handle_compare_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    context.args = [update.message.text]
    return await compare_command(update, context)

async def upload_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    upload_info = """
üìÅ **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤**

–ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö

**üìä –§–æ—Ä–º–∞—Ç—ã**
‚Ä¢ CSV/TSV
‚Ä¢ Excel  
‚Ä¢ JSON

**üéØ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ–ª–µ–π**

**–ò–º—è** ‚Äî name, –∏–º—è, fullname
**–î–æ–ª–∂–Ω–æ—Å—Ç—å** ‚Äî position, –¥–æ–ª–∂–Ω–æ—Å—Ç—å, title  
**–ö–æ–º–ø–∞–Ω–∏—è** ‚Äî company, –∫–æ–º–ø–∞–Ω–∏—è, organization
**–ù–∞–≤—ã–∫–∏** ‚Äî skills, –Ω–∞–≤—ã–∫–∏, competencies

**üöÄ –ü—Ä–æ—Å—Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª**
"""
    await update.message.reply_text(
        upload_info,
        reply_markup=get_main_keyboard()
    )

async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º"""
    telegram_id = str(update.effective_user.id)
    document = update.message.document
    
    if not document:
        await update.message.reply_text("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if document.file_size > 10 * 1024 * 1024:
        await update.message.reply_text("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º 10MB.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
    file_extension = document.file_name.lower().split('.')[-1]
    if file_extension not in ['csv', 'json', 'xlsx', 'xls']:
        await update.message.reply_text("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ CSV, JSON –∏ Excel —Ñ–∞–π–ª—ã.")
        return

    try:
        await update.message.reply_text("üì• –ó–∞–≥—Ä—É–∂–∞—é –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–∞–π–ª...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        file = await context.bot.get_file(document.file_id)
        file_content = await file.download_as_bytearray()
        
        # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result = await file_parser.parse_file(file_content, document.file_name, telegram_id)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if 'error' in result:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
        else:
            success_message = f"""
‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {result.get('experts_added', 0)}
‚Ä¢ –ü—É–±–ª–∏–∫–∞—Ü–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–æ: {result.get('publications_added', 0)}
"""
            await update.message.reply_text(success_message)
            
            if 'analysis' in result and result['analysis']:
                analysis = result['analysis']
                await send_analysis_report(update, analysis)
            
            if result.get('errors'):
                errors_text = "\n".join(result['errors'][:3])
                if len(result['errors']) > 3:
                    errors_text += f"\n... –∏ –µ—â–µ {len(result['errors']) - 3} –æ—à–∏–±–æ–∫"
                await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∏:\n{errors_text}")
            
    except Exception as e:
        logger.error(f"Error handling file for user {telegram_id}: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞.")

async def send_analysis_report(update: Update, analysis: dict):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
    
    if 'insights' in analysis and analysis['insights']:
        insights_text = "üîç **–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤—ã—è–≤–∏–ª:**\n\n" + "\n".join(f"‚Ä¢ {insight}" for insight in analysis['insights'])
        await update.message.reply_text(insights_text, parse_mode='Markdown')
    
    if 'top_companies' in analysis and analysis['top_companies']:
        companies_text = "üè¢ **–¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π:**\n" + "\n".join(f"‚Ä¢ {company}: {count}" for company, count in list(analysis['top_companies'].items())[:5])
        await update.message.reply_text(companies_text)
    
    if 'top_skills' in analysis and analysis['top_skills']:
        skills_text = "üõ† **–¢–æ–ø –Ω–∞–≤—ã–∫–æ–≤:**\n" + "\n".join(f"‚Ä¢ {skill}: {count}" for skill, count in list(analysis['top_skills'].items())[:8])
        await update.message.reply_text(skills_text)
    
    if 'stats' in analysis and analysis['stats']:
        stats = analysis['stats']
        stats_text = f"""
üìà **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:**
‚Ä¢ –í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {stats.get('total_experts', 0)}
‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {stats.get('companies_count', 0)}
‚Ä¢ –ù–∞–≤—ã–∫–æ–≤ –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞: {stats.get('avg_skills_per_expert', 0):.1f}
‚Ä¢ –û—Å–Ω–æ–≤–Ω–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å: {stats.get('most_common_position', 'N/A')}
"""
        await update.message.reply_text(stats_text, parse_mode='Markdown')

async def visualize_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    telegram_id = str(update.effective_user.id)
    try:
        await update.message.chat.send_action(action="typing")
        
        people = db.get_all_people(telegram_id)
        
        if not people:
            await update.message.reply_text(
                "‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.",
                reply_markup=get_main_keyboard()
            )
            return
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        people_data = []
        for person in people:
            people_data.append({
                'name': person.name,
                'position': person.position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'company': person.company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'skills': person.skills,
                'projects': person.projects
            })
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ –¥–ª—è –≥—Ä–∞—Ñ–∞
        connections = []
        for i in range(min(15, len(people_data))):
            for j in range(i + 1, min(15, len(people_data))):
                # –°–≤—è–∑—å –ø–æ –æ–±—â–∏–º –Ω–∞–≤—ã–∫–∞–º
                common_skills = set(people_data[i]['skills']) & set(people_data[j]['skills'])
                if common_skills:
                    connections.append((i, j))
                # –°–≤—è–∑—å –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏
                elif (people_data[i]['company'] == people_data[j]['company'] and 
                      people_data[i]['company'] != '–ù–µ —É–∫–∞–∑–∞–Ω–∞'):
                    connections.append((i, j))
        
        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ 4 —Ç–∏–ø–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        visualizations = [
            ("üìä –ì—Ä–∞—Ñ–∏–∫ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤", visualizer.create_recommendations_chart(people_data[:10])),
            ("üîó –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π", visualizer.create_network_graph(people_data[:15], connections)),
            ("üéØ –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞–≤—ã–∫–æ–≤", visualizer.create_skills_heatmap(people_data[:15])),
            ("üè¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º", visualizer.create_company_distribution(people_data)),
        ]
        
        sent_count = 0
        for title, chart_html in visualizations:
            try:
                with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                    f.write(chart_html)
                    temp_file = f.name

                await update.message.reply_document(
                    document=open(temp_file, 'rb'),
                    filename=f"{title.replace(' ', '_').replace('üìä', '').replace('üîó', '').replace('üéØ', '').replace('üè¢', '')}.html",
                    caption=title
                )
                os.unlink(temp_file)
                sent_count += 1
                
            except Exception as e:
                logger.error(f"Error creating {title}: {e}")
                continue
        
        if sent_count > 0:
            await update.message.reply_text(
                f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∏–∑ 4",
                reply_markup=get_main_keyboard()
            )
        else:
            await update.message.reply_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏",
                reply_markup=get_main_keyboard()
            )
        
    except Exception as e:
        logger.error(f"Error in visualize_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π.",
            reply_markup=get_main_keyboard()
        )

async def cleanup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—á–∏—â–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    telegram_id = str(update.effective_user.id)
    try:
        await update.message.reply_text("üßπ –ò—â—É –∏ —É–¥–∞–ª—è—é –¥—É–±–ª–∏–∫–∞—Ç—ã...")
        
        people_before = db.get_all_people(telegram_id)
        unique_before = len(set(p.name.lower().strip() for p in people_before))
        
        removed_count = db.remove_duplicates()
        
        people_after = db.get_all_people()
        unique_after = len(set(p.name.lower().strip() for p in people_after))
        
        stats_text = f"""
‚úÖ **–û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞**

üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
‚Ä¢ –ó–∞–ø–∏—Å–µ–π –¥–æ –æ—á–∏—Å—Ç–∫–∏: {len(people_before)}
‚Ä¢ –ó–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(people_after)}
‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {removed_count}
‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {unique_after}

üí° **–°—Ç–∞—Ç—É—Å:** {'‚úÖ –ë–∞–∑–∞ –æ—á–∏—â–µ–Ω–∞' if removed_count == 0 else 'üîÑ –ì–æ—Ç–æ–≤–æ'}
"""
        await update.message.reply_text(
            stats_text, 
            parse_mode='Markdown',
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in cleanup_command: {e}")
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}",
            reply_markup=get_main_keyboard()
        )

async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—á–∏—â–∞–µ—Ç –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    try:
        stats_before = db.get_database_stats()
        people_count = stats_before.get('people_count', 0)
        
        if people_count == 0:
            await update.message.reply_text(
                "üì≠ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É–∂–µ –ø—É—Å—Ç–∞!",
                reply_markup=get_main_keyboard()
            )
            return ConversationHandler.END
        
        confirm_keyboard = [['‚úÖ –î–∞, –æ—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É', '‚ùå –ù–µ—Ç, –æ—Ç–º–µ–Ω–∞']]
        reply_markup = ReplyKeyboardMarkup(confirm_keyboard, one_time_keyboard=True)
        
        await update.message.reply_text(
            f"‚ö†Ô∏è **–í–ù–ò–ú–ê–ù–ò–ï: –í—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!**\n\n"
            f"üìä **–¢–µ–∫—É—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
            f"‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {people_count}\n"
            f"‚Ä¢ –ü—É–±–ª–∏–∫–∞—Ü–∏–π: {stats_before.get('publications_count', 0)}\n"
            f"‚Ä¢ –ù–∞–≤—ã–∫–æ–≤: {stats_before.get('unique_skills_count', 0)}\n"
            f"‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–π: {stats_before.get('companies_count', 0)}\n\n"
            f"‚ùå **–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–ª—å–∑—è –æ—Ç–º–µ–Ω–∏—Ç—å!**\n"
            f"–í—ã —É–≤–µ—Ä–µ–Ω—ã —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å?",
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )
        
        context.user_data['clear_stats'] = stats_before
        return 1
        
    except Exception as e:
        logger.error(f"Error in clear_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –æ—á–∏—Å—Ç–∫–∏ –±–∞–∑—ã.",
            reply_markup=get_main_keyboard()
        )
        return ConversationHandler.END

async def confirm_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—á–∏—Å—Ç–∫–∏ –±–∞–∑—ã"""
    user_choice = update.message.text
    
    if user_choice == '‚úÖ –î–∞, –æ—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É':
        try:
            await update.message.reply_text(
                "üßπ –û—á–∏—â–∞—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...", 
                reply_markup=ReplyKeyboardRemove()
            )
            
            stats_before = context.user_data.get('clear_stats', {})
            people_count = stats_before.get('people_count', 0)
            
            success = db.clear_database()
            
            if success:
                await update.message.reply_text(
                    f"‚úÖ **–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞!**\n\n"
                    f"üìä **–£–¥–∞–ª–µ–Ω–æ:**\n"
                    f"‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {people_count}\n\n"
                    f"üìÅ –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ /upload",
                    parse_mode='Markdown',
                    reply_markup=get_main_keyboard()
                )
            else:
                await update.message.reply_text(
                    "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.",
                    reply_markup=get_main_keyboard()
                )
                
        except Exception as e:
            logger.error(f"Error clearing database: {e}")
            await update.message.reply_text(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –±–∞–∑—ã.",
                reply_markup=get_main_keyboard()
            )
            
    else:
        await update.message.reply_text(
            "‚úÖ –û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –æ—Ç–º–µ–Ω–µ–Ω–∞. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.",
            reply_markup=get_main_keyboard()
        )
    
    return ConversationHandler.END

async def cancel_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Ç–º–µ–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É –±–∞–∑—ã"""
    await update.message.reply_text(
        "‚úÖ –û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –æ—Ç–º–µ–Ω–µ–Ω–∞.",
        reply_markup=get_main_keyboard()
    )
    return ConversationHandler.END

async def force_cleanup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    telegram_id = str(update.effective_user.id)
    try:
        await update.message.reply_text("‚ö° –ó–∞–ø—É—Å–∫–∞—é –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É...")
        
        total_removed = 0
        iterations = 0
        
        while iterations < 10:
            removed = db.remove_duplicates()
            total_removed += removed
            iterations += 1
            
            if removed == 0:
                break
        
        people_after = db.get_all_people(telegram_id)
        unique_count = len(set(p.name.lower().strip() for p in people_after))
        
        stats_text = f"""
‚úÖ **–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞**

üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
‚Ä¢ –ò—Ç–µ—Ä–∞—Ü–∏–π –æ—á–∏—Å—Ç–∫–∏: {iterations}
‚Ä¢ –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_removed}
‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {unique_count}
‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {len(people_after)}

üí° **–°—Ç–∞—Ç—É—Å:** {'‚úÖ –ë–∞–∑–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞' if total_removed > 0 else 'üîç –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}
"""
        await update.message.reply_text(
            stats_text, 
            parse_mode='Markdown',
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in force_cleanup_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ.",
            reply_markup=get_main_keyboard()
        )

async def handle_cleanup_options(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –æ–ø—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏"""
    text = update.message.text
    
    if text == 'üßπ –û—á–∏—Å—Ç–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã':
        return await cleanup_command(update, context)
    elif text == '‚ùå –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞':
        return await clear_command(update, context)
    elif text == '‚ùå –û—Ç–º–µ–Ω–∞':
        return await cancel_command(update, context)

async def handle_visualization_options(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    telegram_id = str(update.effective_user.id)
    text = update.message.text
    
    if text == 'üìä –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π':
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:",
            reply_markup=get_cancel_keyboard()
        )
        context.user_data['visualization_type'] = 'recommendations_chart'
        return WAITING_TOPIC
    elif text == 'üîó –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π':
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π:",
            reply_markup=get_cancel_keyboard()
        )
        context.user_data['visualization_type'] = 'network_graph'
        return WAITING_TOPIC
    elif text == 'üéØ –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞':
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –¥–ª—è –≤—Å–µ–π –±–∞–∑—ã
        try:
            await update.message.chat.send_action(action="typing")
            people = db.get_all_people(telegram_id)
            
            if not people:
                await update.message.reply_text("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.")
                return
            
            people_data = []
            for person in people[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                people_data.append({
                    'name': person.name,
                    'skills': person.skills,
                    'company': person.company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                })
            
            heatmap_html = visualizer.create_skills_heatmap(people_data)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                f.write(heatmap_html)
                temp_file = f.name

            await update.message.reply_document(
                document=open(temp_file, 'rb'),
                filename="skills_heatmap.html",
                caption="üéØ –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞–≤—ã–∫–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"
            )
            os.unlink(temp_file)
            
        except Exception as e:
            logger.error(f"Error creating heatmap: {e}")
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã")
            
    elif text == 'üè¢ –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–∞–Ω–∏–π':
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—É –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –≤—Å–µ–π –±–∞–∑—ã
        try:
            await update.message.chat.send_action(action="typing")
            people = db.get_all_people(telegram_id)
            
            if not people:
                await update.message.reply_text("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.")
                return
            
            people_data = []
            for person in people:
                people_data.append({
                    'name': person.name,
                    'company': person.company or '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                    'position': person.position or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
                })
            
            company_html = visualizer.create_company_distribution(people_data)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                f.write(company_html)
                temp_file = f.name

            await update.message.reply_document(
                document=open(temp_file, 'rb'),
                filename="company_distribution.html",
                caption="üè¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º"
            )
            os.unlink(temp_file)
            
        except Exception as e:
            logger.error(f"Error creating company chart: {e}")
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏–∞–≥—Ä–∞–º–º—ã –∫–æ–º–ø–∞–Ω–∏–π")
            
    elif text == '‚ùå –û—Ç–º–µ–Ω–∞':
        return await cancel_command(update, context)
    
    await update.message.reply_text(
        "–ì–æ—Ç–æ–≤–æ! –ß—Ç–æ –µ—â—ë —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å?",
        reply_markup=get_main_keyboard()
    )
    return ConversationHandler.END

async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Ç–º–µ–Ω—è–µ—Ç —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    await update.message.reply_text(
        "‚úÖ –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é.",
        reply_markup=get_main_keyboard()
    )
    return ConversationHandler.END

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫)"""
    text = update.message.text
    
    if text == 'üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏':
        return await recommend_command(update, context)
    elif text == 'üîç –ü–æ–∏—Å–∫':
        return await search_command(update, context)
    elif text == '‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å':
        return await compare_command(update, context)
    elif text == 'üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞':
        return await stats_command(update, context)
    elif text == 'üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ':
        return await upload_command(update, context)
    elif text == 'üõ† –û—á–∏—Å—Ç–∫–∞':
        await update.message.reply_text(
            "üõ† **–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –æ—á–∏—Å—Ç–∫–∏:**",
            reply_markup=get_cleanup_keyboard()
        )
    elif text == 'üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏':
        await update.message.reply_text(
            "üìà **–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:**",
            reply_markup=get_visualization_keyboard()
        )
    elif text == '‚ÑπÔ∏è –ü–æ–º–æ—â—å':
        return await help_command(update, context)
    elif text == '‚ùå –û—Ç–º–µ–Ω–∞':
        return await cancel_command(update, context)
    else:
        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –∫–æ–º–∞–Ω–¥–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if 'visualization_type' in context.user_data:
            return await handle_visualization_input(update, context)
        elif text in ['üßπ –û—á–∏—Å—Ç–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã', '‚ùå –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞']:
            return await handle_cleanup_options(update, context)
        elif text in ['üìä –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π', 'üîó –ì—Ä–∞—Ñ —Å–≤—è–∑–µ–π', 'üéØ –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞', 'üè¢ –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–∞–Ω–∏–π']:
            return await handle_visualization_options(update, context)
        else:
            await update.message.reply_text(
                "–ù–µ –ø–æ–Ω–∏–º–∞—é –∫–æ–º–∞–Ω–¥—É. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é –∏–ª–∏ /help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏.",
                reply_markup=get_main_keyboard()
            )

async def handle_visualization_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
    visualization_type = context.user_data.get('visualization_type')
    topic = update.message.text
    
    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context.user_data.pop('visualization_type', None)
    
    if visualization_type in ['recommendations_chart', 'network_graph']:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        context.args = [topic]
        return await recommend_command(update, context)
    
    await update.message.reply_text(
        "–ì–æ—Ç–æ–≤–æ!",
        reply_markup=get_main_keyboard()
    )
    return ConversationHandler.END
async def my_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    telegram_id = str(update.effective_user.id)
    
    try:
        user_stats = db.get_user_stats(telegram_id)
        db_stats = db.get_database_stats(telegram_id)
        
        if not user_stats:
            await update.message.reply_text(
                "‚ùå –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.",
                reply_markup=get_main_keyboard()
            )
            return
        
        response = f"üë§ –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n\n"
        response += f"üÜî ID: {user_stats['user_id']}\n"
        if user_stats['username']:
            response += f"üë§ Username: @{user_stats['username']}\n"
        if user_stats['first_name']:
            response += f"üìõ –ò–º—è: {user_stats['first_name']}\n"
        response += f"üìÖ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è: {user_stats['created_at'].strftime('%d.%m.%Y %H:%M')}\n\n"
        
        response += f"üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:\n"
        response += f"‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {db_stats['people_count']}\n"
        response += f"‚Ä¢ –ü—É–±–ª–∏–∫–∞—Ü–∏–π: {db_stats['publications_count']}\n"
        response += f"‚Ä¢ –ù–∞–≤—ã–∫–æ–≤: {db_stats['unique_skills_count']}\n"
        response += f"‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–π: {db_stats['companies_count']}\n\n"
        
        response += "üí° –í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω—ã –æ—Ç –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
        
        await update.message.reply_text(
            response,
            reply_markup=get_main_keyboard()
        )
        
    except Exception as e:
        logger.error(f"Error in my_stats_command: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            reply_markup=get_main_keyboard()
        )

def setup_handlers(application):
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("stats", stats_command))
    application.add_handler(CommandHandler("upload", upload_command))
    application.add_handler(CommandHandler("visualize", visualize_command))
    application.add_handler(CommandHandler("cleanup", cleanup_command))
    application.add_handler(CommandHandler("force_cleanup", force_cleanup_command))
    application.add_handler(CommandHandler("mystats", my_stats_command))
    
    # ConversationHandler –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    recommend_conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('recommend', recommend_command),
            MessageHandler(filters.Regex('^üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏$'), recommend_command)
        ],
        states={
            WAITING_TOPIC: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_recommend_topic)]
        },
        fallbacks=[CommandHandler('cancel', cancel_command)]
    )
    application.add_handler(recommend_conv_handler)
    
    # ConversationHandler –¥–ª—è –ø–æ–∏—Å–∫–∞
    search_conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('search', search_command),
            MessageHandler(filters.Regex('^üîç –ü–æ–∏—Å–∫$'), search_command)
        ],
        states={
            WAITING_SEARCH: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_search_query)]
        },
        fallbacks=[CommandHandler('cancel', cancel_command)]
    )
    application.add_handler(search_conv_handler)
    
    # ConversationHandler –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    compare_conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('compare', compare_command),
            MessageHandler(filters.Regex('^‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å$'), compare_command)
        ],
        states={
            WAITING_COMPARE: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_compare_input)]
        },
        fallbacks=[CommandHandler('cancel', cancel_command)]
    )
    application.add_handler(compare_conv_handler)
    
    # ConversationHandler –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    clear_conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('clear', clear_command),
            MessageHandler(filters.Regex('^‚ùå –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞$'), clear_command)
        ],
        states={
            1: [MessageHandler(filters.TEXT & ~filters.COMMAND, confirm_clear)]
        },
        fallbacks=[CommandHandler('cancel', cancel_clear)]
    )
    application.add_handler(clear_conv_handler)
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–∫–Ω–æ–ø–∫–∏)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤
    application.add_handler(MessageHandler(filters.Document.ALL, handle_file))
    
    logger.info("‚úÖ Bot handlers configured with keyboards")